[{"content":" Kafka 的 Rebalance (重平衡) 是 Consumer Group (消费者组) 中的一个核心机制，它用于在 Consumer Group 内部重新分配 Topic 的分区（Partition）所有权。 Rebalance 确保了在集群运行过程中，Consumer Group 里的所有消费者能均匀、独占地消费所有相关的分区。\n1.什么是 Rebalance (重平衡)？ 在 Kafka 中，一个 Consumer Group 消费一个或多个 Topic。每个分区在同一时刻只能被 Consumer Group 内的一个 Consumer 实例消费。 Rebalance 就是 Consumer Group 内部达成一致，确定“谁”来消费“哪个”分区的过程。 1.1 核心目标 负载均衡：将分区均匀地分配给组内所有健康的 Consumer 实例。 高可用性：当有 Consumer 实例失败或退出时，Rebalance 机制会将它之前负责的分区重新分配给组内其他Consumer，确保消费不会中断。 1.2 Rebalance 的过程 整个过程由 Consumer Group 的 Coordinator（协调器，通常是某个 Broker） 负责协调：\n-Join Group (加入组)：新的 Consumer 加入或旧的 Consumer 重新连接时，会向 Coordinator 发送请求。 -Sync Group (同步组)：Coordinator 在收到所有 Consumer 的 Join 请求后，会选出一个 Leader Consumer。 -分配方案：Leader Consumer 负责制定分区到 Consumer 的映射关系（分配策略）。 -执行分配：Coordinator 将分配方案通知给所有 Consumer，各个 Consumer 按照方案开始消费新分配的分区。 2.什么情况下会出现 Rebalance？ 任何导致 Consumer Group 内部成员发生变化或分区信息发生变化的操作，都会触发 Rebalance。\n2.1 Consumer 成员变化 新 Consumer 加入：启动一个新的 Consumer 实例并将其加入到现有 Consumer Group 中，以增加消费能力。 Consumer 退出（正常退出）：一个 Consumer 实例正常关闭，需要将其负责的分区释放出来。 Consumer 崩溃或掉线（非正常退出）： Consumer 实例在发送心跳（Heartbeat）给 Coordinator 的间隔内（session.timeout.ms）没有响应。 Coordinator 认为该 Consumer 死亡，将其踢出 Group，触发 Rebalance。 2.2 Topic/Partition 变化 Topic 分区数发生变化：如果一个 Group 正在消费的 Topic，其分区数量被手动增加，Group 必须进行 Rebalance 来分配新的分区。 Group 订阅的 Topic 列表发生变化：如果 Consumer Group 动态订阅了新的 Topic。 2.3 配置参数变化 心跳超时：如果 Consumer 停止向 Coordinator 发送心跳，并且超出了配置的 session.timeout.ms，Coordinator 将认为 Consumer 实例死亡，触发 Rebalance。 获取分区超时：如果 Consumer 在加入 Group 时，获取分区信息超时，也可能触发 Rebalance 尝试。 注意： Rebalance 是一个“Stop-The-World”操作。在 Rebalance 过程中，Consumer 组会暂停消费，这会引入短暂的消费延迟。因此，频繁的 Rebalance 是需要尽量避免的。\n","permalink":"https://mugong-song.github.io/blog/posts/kafka_rebalance/","summary":"\u003cblockquote\u003e\n\u003cp\u003eKafka 的 Rebalance (重平衡) 是 Consumer Group (消费者组) 中的一个核心机制，它用于在 Consumer Group 内部重新分配 Topic 的分区（Partition）所有权。\nRebalance 确保了在集群运行过程中，Consumer Group 里的所有消费者能均匀、独占地消费所有相关的分区。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"1什么是-rebalance-重平衡\"\u003e1.什么是 Rebalance (重平衡)？\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e在 Kafka 中，一个 Consumer Group 消费一个或多个 Topic。每个分区在同一时刻只能被 Consumer Group 内的一个 Consumer 实例消费。\nRebalance 就是 Consumer Group 内部达成一致，确定“谁”来消费“哪个”分区的过程。\n\u003c/code\u003e\u003c/pre\u003e\u003ch4 id=\"11-核心目标\"\u003e1.1 核心目标\u003c/h4\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e负载均衡：将分区均匀地分配给组内所有健康的 Consumer 实例。\n高可用性：当有 Consumer 实例失败或退出时，Rebalance 机制会将它之前负责的分区重新分配给组内其他Consumer，确保消费不会中断。\n\u003c/code\u003e\u003c/pre\u003e\u003ch4 id=\"12-rebalance-的过程\"\u003e1.2 Rebalance 的过程\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003e整个过程由 Consumer Group 的 Coordinator（协调器，通常是某个 Broker） 负责协调：\u003c/strong\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e-Join Group (加入组)：新的 Consumer 加入或旧的 Consumer 重新连接时，会向 Coordinator 发送请求。\n-Sync Group (同步组)：Coordinator 在收到所有 Consumer 的 Join 请求后，会选出一个 Leader Consumer。\n-分配方案：Leader Consumer 负责制定分区到 Consumer 的映射关系（分配策略）。\n-执行分配：Coordinator 将分配方案通知给所有 Consumer，各个 Consumer 按照方案开始消费新分配的分区。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"2什么情况下会出现-rebalance\"\u003e2.什么情况下会出现 Rebalance？\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e任何导致 Consumer Group 内部成员发生变化或分区信息发生变化的操作，都会触发 Rebalance。\u003c/strong\u003e\u003c/p\u003e","title":"Kafka的rebalance?什么情况下会出现?"},{"content":" Kafka 实现主从同步（即 Leader 副本和 Follower 副本之间的数据同步）是其保证数据高可用性和持久性的核心机制。这个过程是**异步拉取（Pull）的，并由 ISR（同步副本集合）机制严格管理。\n1.异步拉取 与一些数据库的 Push 模式不同，Kafka 的副本同步采用 Pull 模型：\n主动方 (Follower)：Follower 副本是主动方。它会不断地向 Leader 副本发送请求，请求拉取新的消息数据。 拉取单位：Follower 拉取的最小单位是 **日志段（Log Segment）**中的一批消息。 这种拉取模式允许 Follower 控制自己的复制速率。如果 Follower 暂时负载过高，它可以减慢拉取速度，避免被 Leader 的高速写入压垮。 2.关键同步指标 Follower 在同步过程中，会维护和使用两个关键的偏移量（Offset）：\nLEO (Log End Offset)：表示该 Follower 已成功写入本地日志的最新消息的下一个 Offset。 HW (High Watermark)：表示所有 ISR 集合中的副本都已经复制并确认写入的最新消息的下一个 Offset。 重要性：HW 之前的消息对 Consumer 是可见且安全的，而 HW 之后的 Leader 消息对 Consumer 是不可见的，以防 Leader 宕机导致数据丢失。 3.ISR (In-Sync Replicas) 机制的保障 同步副本集合（ISR）是衡量同步状态的核心机制：\nLeader 维护 ISR：Leader 副本负责维护 ISR 列表。ISR 列表包括 Leader 自身和所有与 Leader 保持“同步”的 Follower 副本。 同步判断标准： -Follower 必须在配置的时间阈值（replica.lag.time.max.ms）内持续向 Leader 发送拉取请求。 -Follower 的 LEO 必须与 Leader 的 LEO 保持在一个可接受的范围内。 副本移出：如果 Follower 无法满足上述条件（如网络延迟过高、宕机），它会被 Leader 移出 ISR。 数据持久性保证：当生产者（Producer）设置为 acks=all 时，Leader 必须等待 ISR 中的所有副本都确认写入了消息，才会返回 ACK 成功。这确保了只要 ISR 中有一个副本存活，数据就不会丢失。 4.主从同步流程简述 Follower 发送 Fetch 请求：Follower 向 Leader 发送 Fetch Request，请求从自己的 LEO 开始的新消息。 Leader 发送消息：Leader 从自己的日志中读取从 Follower LEO 开始的消息，并返回给 Follower。 Follower 写入并更新 LEO：Follower 接收到消息后，将其追加写入到自己的本地日志中，并更新自己的 LEO。 Leader 更新 HW：Leader 收到 Follower 的成功响应后，会检查 所有 ISR 副本的 LEO，并更新 HW 为所有副本 LEO 的最小值。 ","permalink":"https://mugong-song.github.io/blog/posts/kafka_sync/","summary":"\u003cblockquote\u003e\n\u003cp\u003eKafka 实现主从同步（即 Leader 副本和 Follower 副本之间的数据同步）是其保证数据高可用性和持久性的核心机制。这个过程是**异步拉取（Pull）的，并由 ISR（同步副本集合）机制严格管理。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"1异步拉取\"\u003e1.异步拉取\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e与一些数据库的 Push 模式不同，Kafka 的副本同步采用 Pull 模型：\u003c/strong\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e主动方 (Follower)：Follower 副本是主动方。它会不断地向 Leader 副本发送请求，请求拉取新的消息数据。\n拉取单位：Follower 拉取的最小单位是 **日志段（Log Segment）**中的一批消息。\n这种拉取模式允许 Follower 控制自己的复制速率。如果 Follower 暂时负载过高，它可以减慢拉取速度，避免被 Leader 的高速写入压垮。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"2关键同步指标\"\u003e2.关键同步指标\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eFollower 在同步过程中，会维护和使用两个关键的偏移量（Offset）：\u003c/strong\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eLEO (Log End Offset)：表示该 Follower 已成功写入本地日志的最新消息的下一个 Offset。\nHW (High Watermark)：表示所有 ISR 集合中的副本都已经复制并确认写入的最新消息的下一个 Offset。\n重要性：HW 之前的消息对 Consumer 是可见且安全的，而 HW 之后的 Leader 消息对 Consumer 是不可见的，以防 Leader 宕机导致数据丢失。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"3isr-in-sync-replicas-机制的保障\"\u003e3.ISR (In-Sync Replicas) 机制的保障\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e同步副本集合（ISR）是衡量同步状态的核心机制：\u003c/strong\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eLeader 维护 ISR：Leader 副本负责维护 ISR 列表。ISR 列表包括 Leader 自身和所有与 Leader 保持“同步”的 Follower 副本。\n同步判断标准：\n -Follower 必须在配置的时间阈值（replica.lag.time.max.ms）内持续向 Leader 发送拉取请求。\n -Follower 的 LEO 必须与 Leader 的 LEO 保持在一个可接受的范围内。\n副本移出：如果 Follower 无法满足上述条件（如网络延迟过高、宕机），它会被 Leader 移出 ISR。\n数据持久性保证：当生产者（Producer）设置为 acks=all 时，Leader 必须等待 ISR 中的所有副本都确认写入了消息，才会返回 ACK 成功。这确保了只要 ISR 中有一个副本存活，数据就不会丢失。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"4主从同步流程简述\"\u003e4.主从同步流程简述\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eFollower 发送 Fetch 请求：Follower 向 Leader 发送 Fetch Request，请求从自己的 LEO 开始的新消息。\nLeader 发送消息：Leader 从自己的日志中读取从 Follower LEO 开始的消息，并返回给 Follower。\nFollower 写入并更新 LEO：Follower 接收到消息后，将其追加写入到自己的本地日志中，并更新自己的 LEO。\nLeader 更新 HW：Leader 收到 Follower 的成功响应后，会检查 所有 ISR 副本的 LEO，并更新 HW 为所有副本 LEO 的最小值。\n\u003c/code\u003e\u003c/pre\u003e","title":"Kafka如何实现主从同步?"},{"content":" 在 Go 语言中，类型断言（Type Assertion） 是一种用于从接口值中提取其底层具体类型的操作。它是 Go 实现多态和类型安全的重要机制之一。\n一、基本语法 value, ok := interfaceVar.(ConcreteType)\ninterfaceVar：一个接口类型的变量 ConcreteType：你期望它实际存储的具体类型（如 int, string, MyStruct 等） value：如果断言成功，就是该类型的值 ok：布尔值，表示断言是否成功\n二、为什么需要类型断言？ Go 的接口（interface）可以存储任何类型的值，但当你想使用这个值的具体方法或字段时，就必须知道它的真实类型。\nvar i interface{} = \u0026ldquo;hello\u0026rdquo;\n// 我知道它是 string，但接口本身不能直接调用 len() s := i.(string) // 类型断言：断言 i 是 string fmt.Println(len(s)) // 现在可以了\n三、两种写法 安全断言（推荐） —— 带 ok 判断 s, ok := i.(string) if ok { fmt.Println(\u0026#34;字符串长度:\u0026#34;, len(s)) } else { fmt.Println(\u0026#34;i 不是一个字符串\u0026#34;) } 优点：不会 panic，适合不确定类型时使用。 直接断言 —— 不检查 ok s := i.(string) // 如果 i 不是 string，会 panic！ 面临的风险：如果类型不匹配，程序会崩溃（panic）。 仅在你100%确定类型时使用。\n四、典型使用场景 场景1：从 interface{} 中取值（比如 JSON 解析）\ndata := map[string]interface{}{ \u0026#34;name\u0026#34;: \u0026#34;Alice\u0026#34;, \u0026#34;age\u0026#34;: 25, } name, _ := data[\u0026#34;name\u0026#34;].(string) age, _ := data[\u0026#34;age\u0026#34;].(int) fmt.Printf(\u0026#34;姓名: %s, 年龄: %d\\n\u0026#34;, name, age) json.Unmarshal 默认把对象解析成 map[string]interface{}，就需要类型断言。\n场景2：处理不同类型的事件\ntype Event interface{} type ClickEvent struct{ X, Y int } type KeyEvent struct{ Key string } func HandleEvent(e Event) { switch v := e.(type) { case ClickEvent: fmt.Printf(\u0026#34;点击事件: (%d, %d)\\n\u0026#34;, v.X, v.Y) case KeyEvent: fmt.Printf(\u0026#34;按键事件: %s\\n\u0026#34;, v.Key) default: fmt.Println(\u0026#34;未知事件\u0026#34;) } } 这里用了 类型选择（type switch），是类型断言的高级形式。\n五、常见错误 错误1：断言失败导致 panic\nvar i interface{} = 42 s := i.(string) // panic: interface is int, not string 优雅做法：\ns, ok := i.(string) if !ok { fmt.Println(\u0026#34;不是字符串\u0026#34;) } 错误2：对 nil 接口断言\nvar i interface{} // nil s, ok := i.(string) // ok == false 即使底层类型是 string，但值是 nil，断言也会失败。\n","permalink":"https://mugong-song.github.io/blog/posts/type_assertion/","summary":"\u003cblockquote\u003e\n\u003cp\u003e在 Go 语言中，类型断言（Type Assertion） 是一种用于从接口值中提取其底层具体类型的操作。它是 Go 实现多态和类型安全的重要机制之一。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"一基本语法\"\u003e一、基本语法\u003c/h2\u003e\n\u003cp\u003evalue, ok := interfaceVar.(ConcreteType)\u003c/p\u003e\n\u003cp\u003einterfaceVar：一个接口类型的变量\nConcreteType：你期望它实际存储的具体类型（如 int, string, MyStruct 等）\nvalue：如果断言成功，就是该类型的值\nok：布尔值，表示断言是否成功\u003c/p\u003e\n\u003ch2 id=\"二为什么需要类型断言\"\u003e二、为什么需要类型断言？\u003c/h2\u003e\n\u003cp\u003eGo 的接口（interface）可以存储任何类型的值，但当你想使用这个值的具体方法或字段时，就必须知道它的真实类型。\u003c/p\u003e\n\u003cp\u003evar i interface{} = \u0026ldquo;hello\u0026rdquo;\u003c/p\u003e\n\u003cp\u003e// 我知道它是 string，但接口本身不能直接调用 len()\ns := i.(string)  // 类型断言：断言 i 是 string\nfmt.Println(len(s))  // 现在可以了\u003c/p\u003e\n\u003ch2 id=\"三两种写法\"\u003e三、两种写法\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e安全断言（推荐） —— 带 ok 判断\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e\n   s, ok := i.(string)\n   if ok {\n   fmt.Println(\u0026#34;字符串长度:\u0026#34;, len(s))\n   } else {\n   fmt.Println(\u0026#34;i 不是一个字符串\u0026#34;)\n   }\n\u003c/code\u003e\u003c/pre\u003e\u003cpre\u003e\u003ccode\u003e优点：不会 panic，适合不确定类型时使用。\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e直接断言 —— 不检查 ok\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e   s := i.(string)  // 如果 i 不是 string，会 panic！\n\u003c/code\u003e\u003c/pre\u003e\u003cpre\u003e\u003ccode\u003e面临的风险：如果类型不匹配，程序会崩溃（panic）。\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e仅在你100%确定类型时使用。\u003c/p\u003e","title":"Type Assertion 类型断言"},{"content":" 分布式锁是分布式系统从“松散运行”走向“协作、可靠运行”的关键桥梁。\n1.什么是分布式锁? 分布式锁是用于在分布式系统中协调多个进程或线程访问共享资源的一种机制，确保在任何时刻只有一个客户端能够操作特定的资源，从而保证数据的一致性。 2.分布式锁的基本要素 无论是基于 Redis、ZooKeeper 还是数据库实现，一个可靠的分布式锁必须满足三个要素： *加锁（Lock）：在资源上设置一个锁的标记。 *设置过期时间（TTL）：防止客户端宕机导致锁无法释放，造成死锁。这是分布式锁与本地锁（如 Java 的 ReentrantLock）最核心的区别。 *释放锁（Unlock）：客户端完成操作后，安全地移除锁。 3.分布式锁面临问题和解决 3.1 死锁 如果客户端在获取锁后，由于某种原因（例如，程序崩溃）未能正常释放锁，导致锁一直被占用，其他客户端无法获取锁，造成死锁。解决方案：在加锁的同时设置过期时间，即使客户端未能正常释放锁，锁也会在过期后自动释放。或者使用 Redlock 算法，提高锁的可靠性，防止死锁。 3.2 锁的误删 -如果客户端 A 获取锁后，由于执行时间过长，导致锁过期自动释放。此时，客户端 B 获取了锁。然后，客户端 A 执行完业务逻辑后，尝试释放锁，但实际上释放的是客户端 B 的锁，造成锁的误删除。解决方案：在加锁时，将锁的值设置为一个唯一标识（例如，UUID），在释放锁时，先判断锁的值是否与自己的唯一标识相等，如果相等，则释放锁；否则，不释放锁。此过程要保证原子性，可以使用 Lua 脚本实现。 -在网络分区的情况下，可能会导致多个进程同时认为自己持有锁。解决方案：在获取锁时生成一个唯一的 UUID，并将其存储在锁的 Key 中。在释放锁时，先检查当前存储的 UUID 是否与自己的 UUID 匹配，只有匹配时才释放锁。 3.3 锁的续期 如果客户端在加锁后，执行时间超过了锁的过期时间，导致锁被自动释放。此时，其他客户端可能会获取锁，造成并发问题。解决方案：客户端在获取锁后，启动一个后台线程，定期检查锁的剩余时间，如果剩余时间小于一定阈值，则使用 EXPIRE 命令续期锁的过期时间。此流程可以自己实现，也可以使用开源框架，例如Redisson 框架不仅提供了自动续期的功能，还可以简化分布式锁的实现。 3.4 锁的竞争 在高并发场景下，多个进程可能会同时竞争锁，导致锁的获取失败率较高。解决方案：可以使用随机退避重试策略，在获取锁失败后，随机等待一段时间后再次重试。 3.5 锁的重入性 如果同一个进程多次尝试获取锁，可能会导致锁的获取失败。解决方案：在锁的 Key 中存储一个计数器，表示当前进程获取锁的次数。每次获取锁时增加计数器，释放锁时减少计数器，只有计数器为 0 时才删除锁的 Key。 3.6 锁的公平性 多个进程同时请求锁时，可能会出现“饥饿”现象，某些进程长时间无法获取锁。解决方案：可以使用 Redis 的 List 数据结构实现排队机制，确保请求锁的进程按照顺序获取锁。或者使用成熟的分布式锁实现库，如 Redisson，它提供了公平锁和可重入锁等功能。 ","permalink":"https://mugong-song.github.io/blog/posts/distributed_lock/","summary":"\u003cblockquote\u003e\n\u003cp\u003e分布式锁是分布式系统从“松散运行”走向“协作、可靠运行”的关键桥梁。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"1什么是分布式锁\"\u003e1.什么是分布式锁?\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e分布式锁是用于在分布式系统中协调多个进程或线程访问共享资源的一种机制，确保在任何时刻只有一个客户端能够操作特定的资源，从而保证数据的一致性。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"2分布式锁的基本要素\"\u003e2.分布式锁的基本要素\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e无论是基于 Redis、ZooKeeper 还是数据库实现，一个可靠的分布式锁必须满足三个要素：\n*加锁（Lock）：在资源上设置一个锁的标记。\n*设置过期时间（TTL）：防止客户端宕机导致锁无法释放，造成死锁。这是分布式锁与本地锁（如 Java 的 ReentrantLock）最核心的区别。\n*释放锁（Unlock）：客户端完成操作后，安全地移除锁。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"3分布式锁面临问题和解决\"\u003e3.分布式锁面临问题和解决\u003c/h3\u003e\n\u003ch4 id=\"31-死锁\"\u003e3.1 死锁\u003c/h4\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e如果客户端在获取锁后，由于某种原因（例如，程序崩溃）未能正常释放锁，导致锁一直被占用，其他客户端无法获取锁，造成死锁。解决方案：在加锁的同时设置过期时间，即使客户端未能正常释放锁，锁也会在过期后自动释放。或者使用 Redlock 算法，提高锁的可靠性，防止死锁。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"32-锁的误删\"\u003e3.2 锁的误删\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e-如果客户端 A 获取锁后，由于执行时间过长，导致锁过期自动释放。此时，客户端 B 获取了锁。然后，客户端 A 执行完业务逻辑后，尝试释放锁，但实际上释放的是客户端 B 的锁，造成锁的误删除。解决方案：在加锁时，将锁的值设置为一个唯一标识（例如，UUID），在释放锁时，先判断锁的值是否与自己的唯一标识相等，如果相等，则释放锁；否则，不释放锁。此过程要保证原子性，可以使用 Lua 脚本实现。\n-在网络分区的情况下，可能会导致多个进程同时认为自己持有锁。解决方案：在获取锁时生成一个唯一的 UUID，并将其存储在锁的 Key 中。在释放锁时，先检查当前存储的 UUID 是否与自己的 UUID 匹配，只有匹配时才释放锁。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"33-锁的续期\"\u003e3.3 锁的续期\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e如果客户端在加锁后，执行时间超过了锁的过期时间，导致锁被自动释放。此时，其他客户端可能会获取锁，造成并发问题。解决方案：客户端在获取锁后，启动一个后台线程，定期检查锁的剩余时间，如果剩余时间小于一定阈值，则使用 EXPIRE 命令续期锁的过期时间。此流程可以自己实现，也可以使用开源框架，例如Redisson 框架不仅提供了自动续期的功能，还可以简化分布式锁的实现。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"34-锁的竞争\"\u003e3.4 锁的竞争\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e在高并发场景下，多个进程可能会同时竞争锁，导致锁的获取失败率较高。解决方案：可以使用随机退避重试策略，在获取锁失败后，随机等待一段时间后再次重试。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"35-锁的重入性\"\u003e3.5 锁的重入性\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e如果同一个进程多次尝试获取锁，可能会导致锁的获取失败。解决方案：在锁的 Key 中存储一个计数器，表示当前进程获取锁的次数。每次获取锁时增加计数器，释放锁时减少计数器，只有计数器为 0 时才删除锁的 Key。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"36-锁的公平性\"\u003e3.6 锁的公平性\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e多个进程同时请求锁时，可能会出现“饥饿”现象，某些进程长时间无法获取锁。解决方案：可以使用 Redis 的 List 数据结构实现排队机制，确保请求锁的进程按照顺序获取锁。或者使用成熟的分布式锁实现库，如 Redisson，它提供了公平锁和可重入锁等功能。\n\u003c/code\u003e\u003c/pre\u003e","title":"了解分布式锁吗?"},{"content":" 栈分配和堆分配确实都发生在“对象分配器”的分配阶段， 但它们走的是不同的路径： 栈分配走的是编译期静态分配； 堆分配走的是运行时对象分配器（runtime.mallocgc）。\n1.程序启动阶段 Go 运行时启动时（runtime 初始化），会： 向操作系统申请一大块虚拟内存（称为 arena）； 由 页分配器（page allocator） 管理这块内存； 构建堆内存管理结构（mheap、mcentral、mcache）。 这部分只是“预留”内存，真正的对象分配还没发生。\n2.用户程序触发分配（对象分配阶段） 当用户代码中创建变量时，比如：\nx := MyStruct{} 编译器会在编译阶段决定这个对象是： 分配在栈上（stack allocation） 还是分配在堆上（heap allocation） 这个决策是通过 逃逸分析（Escape Analysis） 完成的。\n3.栈分配的过程 如果编译器认为对象只在当前函数作用域内使用，不会被外部引用： 这个对象会直接分配在栈上； 不会调用运行时的内存分配器； 栈内存是随函数调用帧自动增长/释放的； GC 不需要扫描或回收它。 \u0026gt; 关键：栈分配是编译期确定的，性能最好。 4.堆分配的过程 如果对象被闭包引用、返回地址或传递给其他 goroutine，则会发生逃逸： 编译器在生成代码时，会调用运行时的分配器 runtime.mallocgc； mallocgc 会从当前 P 的 mcache 尝试获取一个合适的 span； 若 mcache 缓存不足，就从 mcentral → mheap 逐层申请； 分配完成后，GC 会在堆上追踪这个对象。 \u0026gt;关键：堆分配是运行时动态完成的，涉及 GC 管理。 5.回收阶段 当对象不再被引用时，GC 会标记并清除； 被清除的内存重新回收到 mcache / mcentral / mheap； 长期未使用的页可能由scavenger（拾荒器）归还给 OS。 6.对比栈和堆分配 类型 分配阶段 分配位置 分配速度 是否由 GC 管理 是否逃逸 栈分配 编译期（静态） 每个 goroutine 的调用栈 极快 否 否 堆分配 运行时（动态） 运行时堆（mheap） 慢 是 是 ","permalink":"https://mugong-song.github.io/blog/posts/memory_management/","summary":"\u003cblockquote\u003e\n\u003cp\u003e栈分配和堆分配确实都发生在“对象分配器”的分配阶段，\n但它们走的是不同的路径：\n栈分配走的是编译期静态分配；\n堆分配走的是运行时对象分配器（runtime.mallocgc）。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"1程序启动阶段\"\u003e1.程序启动阶段\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e Go 运行时启动时（runtime 初始化），会：\n向操作系统申请一大块虚拟内存（称为 arena）；\n由 页分配器（page allocator） 管理这块内存；\n构建堆内存管理结构（mheap、mcentral、mcache）。\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003e这部分只是“预留”内存，真正的对象分配还没发生。\u003c/strong\u003e\u003c/p\u003e\n\u003ch3 id=\"2用户程序触发分配对象分配阶段\"\u003e2.用户程序触发分配（对象分配阶段）\u003c/h3\u003e\n\u003cp\u003e当用户代码中创建变量时，比如：\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ex := MyStruct{}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e编译器会在编译阶段决定这个对象是：\n分配在栈上（stack allocation）\n还是分配在堆上（heap allocation）\n这个决策是通过 逃逸分析（Escape Analysis） 完成的。\u003c/p\u003e\n\u003ch3 id=\"3栈分配的过程\"\u003e3.栈分配的过程\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e如果编译器认为对象只在当前函数作用域内使用，不会被外部引用：\n这个对象会直接分配在栈上；\n不会调用运行时的内存分配器；\n栈内存是随函数调用帧自动增长/释放的；\nGC 不需要扫描或回收它。\n\u0026gt; 关键：栈分配是编译期确定的，性能最好。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"4堆分配的过程\"\u003e4.堆分配的过程\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e如果对象被闭包引用、返回地址或传递给其他 goroutine，则会发生逃逸：\n编译器在生成代码时，会调用运行时的分配器 runtime.mallocgc；\nmallocgc 会从当前 P 的 mcache 尝试获取一个合适的 span；\n若 mcache 缓存不足，就从 mcentral → mheap 逐层申请；\n分配完成后，GC 会在堆上追踪这个对象。\n\u0026gt;关键：堆分配是运行时动态完成的，涉及 GC 管理。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"5回收阶段\"\u003e5.回收阶段\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e当对象不再被引用时，GC 会标记并清除；\n被清除的内存重新回收到 mcache / mcentral / mheap；\n长期未使用的页可能由scavenger（拾荒器）归还给 OS。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"6对比栈和堆分配\"\u003e6.对比栈和堆分配\u003c/h3\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e类型\u003c/th\u003e\n          \u003cth\u003e分配阶段\u003c/th\u003e\n          \u003cth\u003e分配位置\u003c/th\u003e\n          \u003cth\u003e分配速度\u003c/th\u003e\n          \u003cth\u003e是否由 GC 管理\u003c/th\u003e\n          \u003cth\u003e是否逃逸\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e栈分配\u003c/td\u003e\n          \u003ctd\u003e编译期（静态）\u003c/td\u003e\n          \u003ctd\u003e每个 goroutine 的调用栈\u003c/td\u003e\n          \u003ctd\u003e极快\u003c/td\u003e\n          \u003ctd\u003e否\u003c/td\u003e\n          \u003ctd\u003e否\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e堆分配\u003c/td\u003e\n          \u003ctd\u003e运行时（动态）\u003c/td\u003e\n          \u003ctd\u003e运行时堆（mheap）\u003c/td\u003e\n          \u003ctd\u003e慢\u003c/td\u003e\n          \u003ctd\u003e是\u003c/td\u003e\n          \u003ctd\u003e是\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e","title":"你了解内存管理吗?"},{"content":"1.为什么会不一致 ？ Redis 是缓存层，数据库是持久层。 二者数据可能不一致的原因包括： 更新数据库成功，但更新缓存失败； 缓存提前过期； 并发写操作覆盖（顺序问题）； 异步更新延迟。 2.更新策略 2.1 Cache Aside（旁路缓存） 读操作 1. 读缓存 2. 如果缓存不存在 ,再读数据库 3. 将数据写入缓存（设置过期时间） 写操作: 先更新数据库,再删除缓存 缺点:删除缓存可能失败；删除顺序不当会不一致 2.2 Read/Write Through（读写穿透） 应用不直接访问DB，所有读写都经由缓存代理完成 缺点:实现复杂，性能略低\t2.3 Write Behind（异步写回） 只写缓存，由缓存异步刷回数据库\t缺点:容易丢数据\t3.处理并发问题 3.1延迟双删策略（Double Delete） 1. 更新数据库； 2. 删除缓存； 3. 延迟 500ms 再删一次缓存。 //可以应对并发中缓存被“脏写”回的情况。 3.2异步消息队列（MQ） 数据更新时发送 MQ 消息，异步同步缓存状态。\n3.3分布式锁 保证更新操作串行执行，避免交叉覆盖。\n","permalink":"https://mugong-song.github.io/blog/posts/redis_db_consitent/","summary":"\u003ch3 id=\"1为什么会不一致-\"\u003e1.为什么会不一致 ？\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eRedis 是缓存层，数据库是持久层。\n二者数据可能不一致的原因包括：\n更新数据库成功，但更新缓存失败；\n缓存提前过期；\n并发写操作覆盖（顺序问题）；\n异步更新延迟。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"2更新策略\"\u003e2.更新策略\u003c/h3\u003e\n\u003ch4 id=\"21-cache-aside旁路缓存\"\u003e2.1 Cache Aside（旁路缓存）\u003c/h4\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e读操作\n1. 读缓存\n2. 如果缓存不存在 ,再读数据库\n3. 将数据写入缓存（设置过期时间）\n写操作: 先更新数据库,再删除缓存\n\n缺点:删除缓存可能失败；删除顺序不当会不一致\n\u003c/code\u003e\u003c/pre\u003e\u003ch4 id=\"22-readwrite-through读写穿透\"\u003e2.2 Read/Write Through（读写穿透）\u003c/h4\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e应用不直接访问DB，所有读写都经由缓存代理完成\n\n缺点:实现复杂，性能略低\t\n\u003c/code\u003e\u003c/pre\u003e\u003ch4 id=\"23-write-behind异步写回\"\u003e2.3 Write Behind（异步写回）\u003c/h4\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e只写缓存，由缓存异步刷回数据库\t\n\n缺点:容易丢数据\t\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"3处理并发问题\"\u003e3.处理并发问题\u003c/h3\u003e\n\u003ch4 id=\"31延迟双删策略double-delete\"\u003e3.1延迟双删策略（Double Delete）\u003c/h4\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e1. 更新数据库；\n2. 删除缓存；\n3. 延迟 500ms 再删一次缓存。\n//可以应对并发中缓存被“脏写”回的情况。\n\u003c/code\u003e\u003c/pre\u003e\u003ch4 id=\"32异步消息队列mq\"\u003e3.2异步消息队列（MQ）\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003e数据更新时发送 MQ 消息，异步同步缓存状态。\u003c/strong\u003e\u003c/p\u003e\n\u003ch4 id=\"33分布式锁\"\u003e3.3分布式锁\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003e保证更新操作串行执行，避免交叉覆盖。\u003c/strong\u003e\u003c/p\u003e","title":"如何保证 Redis 与数据库的数据一致性?"},{"content":"1.什么是“重锁”（Heavy Lock） 在 Go 性能调优或并发编程中，我们常说的 “重锁”（heavy lock）不是官方术语，而是一个工程上的概念，指的是：锁竞争严重、临界区较大、持锁时间较长的互斥锁（sync.Mutex）。\n1.多个 goroutine 同时频繁地去争夺同一把锁；\n2.加锁的代码块中做了比较“重”的操作（比如 I/O、JSON 编码、数据库操作）；\n导致 goroutine 阻塞、上下文切换频繁，最终造成性能瓶颈。\n2.为什么会出现“重锁”问题 1.临界区太大（锁保护的范围过广）；\n2.频繁写操作导致锁争用；\n3.使用全局变量或共享状态；\n4.没有分片（sharding）或局部化锁机制；\n5.锁中包含耗时操作（例如网络请求、磁盘 I/O）。\nvar mu sync.Mutex var cache = make(map[string]string) func Set(k, v string) { mu.Lock() defer mu.Unlock() cache[k] = v } #当高并发调用 Set() 时，所有 goroutine 都在争抢同一把 mu，这就形成“重锁”。 3.优化思路与替代方案 3.1 使用 sync.Map 适用于读多写少的场景：\nvar m sync.Map m.Store(\u0026quot;a\u0026quot;, 1) v, _ := m.Load(\u0026quot;a\u0026quot;) #sync.Map 内部采用分片和原子操作，避免了全局锁竞争。 3.2 使用原子操作（sync/atomic） 适用于简单的计数、标志位等操作：\nvar count int64 atomic.AddInt64(\u0026amp;count, 1) #无锁化操作，性能更高，且不阻塞其他 goroutine。 3.3 优化锁粒度（细化锁） 将一把全局锁拆分成多把局部锁：\nvar locks [16]sync.Mutex func getLock(key string) *sync.Mutex { return \u0026amp;locks[hash(key)%16] } #减少锁争用，提高并发性能。 ","permalink":"https://mugong-song.github.io/blog/posts/lock/","summary":"\u003ch3 id=\"1什么是重锁heavy-lock\"\u003e1.什么是“重锁”（Heavy Lock）\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003e在 Go 性能调优或并发编程中，我们常说的 “重锁”（heavy lock）不是官方术语，而是一个工程上的概念，指的是：锁竞争严重、临界区较大、持锁时间较长的互斥锁（sync.Mutex）。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e1.多个 goroutine 同时频繁地去争夺同一把锁；\u003c/p\u003e\n\u003cp\u003e2.加锁的代码块中做了比较“重”的操作（比如 I/O、JSON 编码、数据库操作）；\u003c/p\u003e\n\u003cp\u003e导致 goroutine 阻塞、上下文切换频繁，最终造成性能瓶颈。\u003c/p\u003e\n\u003ch3 id=\"2为什么会出现重锁问题\"\u003e2.为什么会出现“重锁”问题\u003c/h3\u003e\n\u003cp\u003e1.临界区太大（锁保护的范围过广）；\u003c/p\u003e\n\u003cp\u003e2.频繁写操作导致锁争用；\u003c/p\u003e\n\u003cp\u003e3.使用全局变量或共享状态；\u003c/p\u003e\n\u003cp\u003e4.没有分片（sharding）或局部化锁机制；\u003c/p\u003e\n\u003cp\u003e5.锁中包含耗时操作（例如网络请求、磁盘 I/O）。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e    var mu sync.Mutex\n    var cache = make(map[string]string)\n    \n    func Set(k, v string) {\n    mu.Lock()\n    defer mu.Unlock()\n    cache[k] = v\n    }\n    #当高并发调用 Set() 时，所有 goroutine 都在争抢同一把 mu，这就形成“重锁”。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"3优化思路与替代方案\"\u003e3.优化思路与替代方案\u003c/h3\u003e\n\u003ch4 id=\"31-使用-syncmap\"\u003e3.1 使用 sync.Map\u003c/h4\u003e\n\u003cp\u003e适用于读多写少的场景：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003evar m sync.Map\nm.Store(\u0026quot;a\u0026quot;, 1)\nv, _ := m.Load(\u0026quot;a\u0026quot;)\n#sync.Map 内部采用分片和原子操作，避免了全局锁竞争。\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4 id=\"32-使用原子操作syncatomic\"\u003e3.2 使用原子操作（sync/atomic）\u003c/h4\u003e\n\u003cp\u003e适用于简单的计数、标志位等操作：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003evar count int64\natomic.AddInt64(\u0026amp;count, 1)\n#无锁化操作，性能更高，且不阻塞其他 goroutine。\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4 id=\"33-优化锁粒度细化锁\"\u003e3.3 优化锁粒度（细化锁）\u003c/h4\u003e\n\u003cp\u003e将一把全局锁拆分成多把局部锁：\u003c/p\u003e","title":"什么是“重锁” Heavy Lock?"},{"content":" 零拷贝（Zero-Copy）是一种计算机操作技术，主要应用于高性能网络和文件 I/O 领域。它的核心目标是减少 CPU 在传输数据时进行不必要的内存数据拷贝，以及减少用户空间和内核空间之间的上下文切换次数。\n1.核心原理 ？ 在传统的 I/O 操作中，数据通常需要经历四次拷贝才能完成传输（例如将文件通过网络发送给客户端）： 第一次拷贝： 数据从磁盘读取到操作系统内核的缓冲区（通常是 Page Cache）。 第二次拷贝： 数据从内核缓冲区拷贝到应用程序的用户缓冲区。 第三次拷贝： 数据从用户缓冲区拷贝回内核的 Socket 缓冲区。 第四次拷贝： 数据从 Socket 缓冲区拷贝到网络接口卡（NIC）的缓冲区，最终发送。 零拷贝技术通过特定的系统调用和硬件支持，消除了步骤 2 和 3 的 CPU 拷贝。\n2.常见的零拷贝实现方式 2.1 sendfile 这是最常见的零拷贝实现，例如 Apache Kafka 和 Nginx 等 Web 服务器广泛使用它来高效传输文件数据。 实现机制： 它将数据从一个文件描述符直接传输到另一个文件描述符（例如从磁盘文件 FD 到网络 Socket FD）。 消除拷贝： sendfile 允许数据在内核缓冲区和 Socket 缓冲区之间直接传输，跳过了用户缓冲区，从而消除了两次 CPU 拷贝。 2.2 内存映射文件 (mmap) 内存映射文件技术通过 mmap 系统调用将文件内容直接映射到进程的虚拟地址空间。 实现： 应用程序通过指针直接读写映射的内存地址，而这个地址对应的物理内存正是内核缓冲区。 消除拷贝： 它消除了数据从内核缓冲区拷贝到用户缓冲区的步骤，因为内核缓冲区和用户空间共享了同一块物理内存。 3.零拷贝的优势 降低 CPU 开销： 减少了 CPU 进行数据拷贝的工作量。 减少延迟： 数据传输路径更短。 提高吞吐量： 特别适用于高并发、I/O 密集型的场景，如文件服务器、Web 服务器和消息中间件（如 Kafka）。 ","permalink":"https://mugong-song.github.io/blog/posts/zero_copes/","summary":"\u003cblockquote\u003e\n\u003cp\u003e零拷贝（Zero-Copy）是一种计算机操作技术，主要应用于高性能网络和文件 I/O 领域。它的核心目标是减少 CPU 在传输数据时进行不必要的内存数据拷贝，以及减少用户空间和内核空间之间的上下文切换次数。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"1核心原理-\"\u003e1.核心原理 ？\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e在传统的 I/O 操作中，数据通常需要经历四次拷贝才能完成传输（例如将文件通过网络发送给客户端）：\n第一次拷贝： 数据从磁盘读取到操作系统内核的缓冲区（通常是 Page Cache）。\n第二次拷贝： 数据从内核缓冲区拷贝到应用程序的用户缓冲区。\n第三次拷贝： 数据从用户缓冲区拷贝回内核的 Socket 缓冲区。\n第四次拷贝： 数据从 Socket 缓冲区拷贝到网络接口卡（NIC）的缓冲区，最终发送。\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003e零拷贝技术通过特定的系统调用和硬件支持，消除了步骤 2 和 3 的 CPU 拷贝。\u003c/strong\u003e\u003c/p\u003e\n\u003ch3 id=\"2常见的零拷贝实现方式\"\u003e2.常见的零拷贝实现方式\u003c/h3\u003e\n\u003ch4 id=\"21-sendfile\"\u003e2.1 sendfile\u003c/h4\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e这是最常见的零拷贝实现，例如 Apache Kafka 和 Nginx 等 Web 服务器广泛使用它来高效传输文件数据。\n实现机制： 它将数据从一个文件描述符直接传输到另一个文件描述符（例如从磁盘文件 FD 到网络 Socket FD）。\n消除拷贝： sendfile 允许数据在内核缓冲区和 Socket 缓冲区之间直接传输，跳过了用户缓冲区，从而消除了两次 CPU 拷贝。\n\u003c/code\u003e\u003c/pre\u003e\u003ch4 id=\"22-内存映射文件-mmap\"\u003e2.2 内存映射文件 (mmap)\u003c/h4\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e内存映射文件技术通过 mmap 系统调用将文件内容直接映射到进程的虚拟地址空间。\n实现： 应用程序通过指针直接读写映射的内存地址，而这个地址对应的物理内存正是内核缓冲区。\n消除拷贝： 它消除了数据从内核缓冲区拷贝到用户缓冲区的步骤，因为内核缓冲区和用户空间共享了同一块物理内存。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"3零拷贝的优势\"\u003e3.零拷贝的优势\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e降低 CPU 开销： 减少了 CPU 进行数据拷贝的工作量。\n减少延迟： 数据传输路径更短。\n提高吞吐量： 特别适用于高并发、I/O 密集型的场景，如文件服务器、Web 服务器和消息中间件（如 Kafka）。\n\u003c/code\u003e\u003c/pre\u003e","title":"什么是零拷贝?"},{"content":" 👋 简介 你好！我是 Mumu，一名热爱技术与写作的创作者。\n这里记录我的学习笔记、项目、随笔与资源分享。\n我热衷于探索高效开发、开源工具和知识体系构建。\n⚡️ 速览 职业：软件工程师 / 后端 所在地：中国🇨🇳 擅长：Go/Docker/Kubernetes/Redis/RabbitMQ/Kafka\u0026hellip; 邮箱：tomsfamily01@gmail.com 🧭 详细介绍 我喜欢把复杂的问题拆解成可执行的小步骤——这同样适用于代码和生活。\n我的博客主要分享：实践记录、问题复现与解决方案、工具推荐与配置教程。\n如果你是初学者，欢迎从我的标签页（如 #入门）开始；\n如果你是同行，也欢迎与我交流合作。\n🚀 项目与成果 项目 A — GitHub 链接：简短说明 项目 B — GitHub 链接：简短说明 📫 联系我 📧 邮箱：tomsfamily01@gmail.com 🐙 GitHub：mugong-song 🌅 座右铭 悟已往之不谏，知来者之可追。\n—— 陶渊明《归去来兮辞》\n","permalink":"https://mugong-song.github.io/blog/about/","summary":"关于我的简单介绍、联系方式和创作理念。","title":"About — 关于我"},{"content":"1.垃圾回收的认识 1.1垃圾回收是什么，有什么作用 GC，全称 Garbage Collection，即垃圾回收，是一种自动内存管理的机制。 当程序向操作系统申请的内存不再需要时，垃圾回收主动将其回收并供其他代码进行内存申请 时候复用，或者将其归还给操作系统，这种针对内存级别资源的自动回收过程，即为垃圾回收。而 负责垃圾回收的程序组件，即为垃圾回收器。 垃圾回收其实是一个完美的“Simplicity is Complicated”的例子。一方面，程序员受益于 GC，也不再需要对内存进行手动的申请和释放操作，GC 在程序运行时自动释放残留的内存。另一 方面，GC 对程序员几乎不可见，仅在程序需要进行特殊优化时，通过提供可调控的 API，对 GC 的运行时机、运行开销进行把控的时候才得以现身。 通常，垃圾回收器的执行过程被划分为两个半独立的组件：\n1）赋值器（Mutator）：这一名称本质上是在指代用户态的代码。因为对垃圾回收器而言，用户 态的代码仅仅只修改对象之间的引用关系，也就是在对象图（对象之间引用关系的一个有向图）上 进行操作。 2）回收器（Collector）：负责执行垃圾回收的代码。\n1.2常见的垃圾回收的实现方式有哪些，Go使用的是什么 所有的 GC 算法其存在形式可以归结为追踪（Tracing）和引用计数（Reference Counting）这 两种形式的混合运用。\n（1）追踪式 GC 从根对象出发，根据对象之间的引用信息，一步步推进直到扫描完毕整个堆并确定需要保留的 对象，从而回收所有可回收的对象。Go、 Java、V8 对 JavaScript 的实现等均为追踪式 GC。 （2）引用计数式 GC 每个对象自身包含一个被引用的计数器，当计数器归零时自动得到回收。因为此方法缺陷较 多，在追求高性能时通常不被应用。Python、Objective-C 等均为引用计数式 GC。 比较常见的 GC 实现方式包括：\n1）追踪式，分为多种不同类型，例如： 标记清扫：从根对象出发，将确定存活的对象进行标记，并清扫可以回收的对象。 标记整理：为了解决内存碎片问题而提出，在标记过程中，将对象尽可能整理到一块连续的内 存上。 2)增量式：将标记与清扫的过程分批执行，每次执行很小的部分，从而增量推进垃圾回收，达到 近似实时、几乎无停顿的效果。 3)增量整理：在增量式的基础上，增加对对象的整理过程。 4)分代式：将对象根据存活时间的长短进行分类，存活时间小于某个值的为年轻代，存活时间大于 某个值的为老年代，永远不会参与回收的对象为永久代。并根据分代假设（如果一个对象存活时间不 长则倾向于被回收，如果一个对象已经存活很长时间则倾向于存活更长时间）对对象进行回收。 ","permalink":"https://mugong-song.github.io/blog/posts/garbage-collection/","summary":"\u003ch3 id=\"1垃圾回收的认识\"\u003e1.垃圾回收的认识\u003c/h3\u003e\n\u003ch3 id=\"11垃圾回收是什么有什么作用\"\u003e1.1垃圾回收是什么，有什么作用\u003c/h3\u003e\n\u003cp\u003eGC，全称 Garbage Collection，即垃圾回收，是一种自动内存管理的机制。\n当程序向操作系统申请的内存不再需要时，垃圾回收主动将其回收并供其他代码进行内存申请\n时候复用，或者将其归还给操作系统，这种针对内存级别资源的自动回收过程，即为垃圾回收。而\n负责垃圾回收的程序组件，即为垃圾回收器。\n垃圾回收其实是一个完美的“Simplicity is Complicated”的例子。一方面，程序员受益于\nGC，也不再需要对内存进行手动的申请和释放操作，GC 在程序运行时自动释放残留的内存。另一\n方面，GC 对程序员几乎不可见，仅在程序需要进行特殊优化时，通过提供可调控的 API，对 GC\n的运行时机、运行开销进行把控的时候才得以现身。\n通常，垃圾回收器的执行过程被划分为两个半独立的组件：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e1）赋值器（Mutator）：这一名称本质上是在指代用户态的代码。因为对垃圾回收器而言，用户\n态的代码仅仅只修改对象之间的引用关系，也就是在对象图（对象之间引用关系的一个有向图）上\n进行操作。\n2）回收器（Collector）：负责执行垃圾回收的代码。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"12常见的垃圾回收的实现方式有哪些go使用的是什么\"\u003e1.2常见的垃圾回收的实现方式有哪些，Go使用的是什么\u003c/h3\u003e\n\u003cp\u003e所有的 GC 算法其存在形式可以归结为追踪（Tracing）和引用计数（Reference Counting）这\n两种形式的混合运用。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e（1）追踪式 GC\n从根对象出发，根据对象之间的引用信息，一步步推进直到扫描完毕整个堆并确定需要保留的\n对象，从而回收所有可回收的对象。Go、 Java、V8 对 JavaScript 的实现等均为追踪式 GC。\n（2）引用计数式 GC\n每个对象自身包含一个被引用的计数器，当计数器归零时自动得到回收。因为此方法缺陷较\n多，在追求高性能时通常不被应用。Python、Objective-C 等均为引用计数式 GC。\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e比较常见的 GC 实现方式包括：\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e1）追踪式，分为多种不同类型，例如：\n标记清扫：从根对象出发，将确定存活的对象进行标记，并清扫可以回收的对象。\n标记整理：为了解决内存碎片问题而提出，在标记过程中，将对象尽可能整理到一块连续的内\n存上。\n2)增量式：将标记与清扫的过程分批执行，每次执行很小的部分，从而增量推进垃圾回收，达到\n近似实时、几乎无停顿的效果。\n3)增量整理：在增量式的基础上，增加对对象的整理过程。\n4)分代式：将对象根据存活时间的长短进行分类，存活时间小于某个值的为年轻代，存活时间大于\n某个值的为老年代，永远不会参与回收的对象为永久代。并根据分代假设（如果一个对象存活时间不\n长则倾向于被回收，如果一个对象已经存活很长时间则倾向于存活更长时间）对对象进行回收。\n\u003c/code\u003e\u003c/pre\u003e","title":"垃圾回收机制 Garbage Collection"},{"content":" chan 是 Go 语言并发编程中最核心的概念之一，它是 Channel（通道） 类型的关键字缩写。\nChannel 的设计理念源于通信顺序进程（CSP, Communicating Sequential Processes），它提供了一种安全、同步的方式，让不同的 Goroutine（并发执行的“工人”）之间可以进行通信和数据交换。\n1.什么是 chan (通道)？ Channel 可以被理解为一个管道或队列，它具有以下核心特性：\n类型安全： Channel 只能传输它在创建时指定的特定类型的数据。 例如：chan int 只能传输 int 整数。 同步机制： Channel 默认会阻塞发送和接收操作，直到另一端准备好。 并发安全： Go 运行时保证了对 Channel 的发送和接收操作是线程安全的，无需额外的锁（sync.Mutex）。 2.chan 怎么使用？ 使用 Channel 主要分为三个步骤：创建、发送、接收。\n2.1 创建 Channel 使用 make 函数创建 Channel。\n//无缓冲通道 (Unbuffered) ch := make(chan Type) //容量为 0。发送和接收操作必须同时准备好，否则先执行的操作会一直阻塞，直到另一个操作发生。用于严格的同步。 ch := make(chan Type, N) //有缓冲通道 (Buffered) //容量为 N。通道可以存储 N个元素。只有当通道满了（发送）或空了（接收）时，操作才会阻塞。用于解耦和提高吞吐量。 dataCh := make(chan string) // 无缓冲，用于同步信号 taskCh := make(chan int, 10) // 有缓冲，容量为 10，用于传输任务 类型 语法 目的 切片 make([]Type, length, capacity) 分配底层数组，设置切片的长度和容量。 映射 make(map[KeyType]ValueType, capacity) 分配和初始化哈希表结构。 通道 make(chan Type, capacity) 创建通道并设置其缓冲大小。 2.2 发送数据 使用箭头操作符 \u0026lt;- 将数据发送到 Channel。\nch \u0026lt;- value //示例： taskCh \u0026lt;- 5 // 将整数 5 发送到 taskCh~~~ 2.3 接收数据 使用箭头操作符 \u0026lt;- 从 Channel 接收数据。\nvalue := \u0026lt;-ch // 接收数据，并赋值给 value value, ok := \u0026lt;-ch // 接收数据，并检查通道是否已关闭 示例 // 接收并赋值 taskId := \u0026lt;-taskCh // 接收并检查状态（常用于循环接收） id, open := \u0026lt;-taskCh if !open { // 通道已被关闭且数据已取完 } 3.使用的时候要注意什么？ 使用 Channel 必须非常小心，错误的用法可能导致程序死锁、数据丢失或性能问题。\n3.1避免死锁 (Deadlock) 死锁是使用 Channel 时最常见的问题。 如果一个 Goroutine 试图发送数据到一个无缓冲通道，但没有另一个 Goroutine 准备好接收，该 Goroutine 就会永远阻塞，Go 运行时会检测到这种情况并报告致命错误：fatal error: all goroutines are asleep - deadlock!\n规则： 无缓冲通道 总是需要一个发送方和一个接收方同时在场。 避免： 绝对不要在同一个 Goroutine 中对无缓冲通道进行发送和接收操作。 3.2关闭 Channel Channel 可以通过 close(ch) 函数关闭，表示不会再有数据发送。\n只能发送方关闭： 应该由发送方来关闭 Channel，而不是接收方。 重复关闭 panic： 重复关闭一个 Channel 会导致 panic。 关闭后的接收： 关闭后，接收方仍可以接收到通道中剩余的数据。当数据取完后，接收操作会立即返回该类型的零值，ok 状态为 false。 3.3缓冲区的误解 有缓冲通道 不是无限队列。一旦缓冲区满了，发送操作仍然会阻塞。 合理设置缓冲区大小是提高性能的关键，但过大或过小都可能带来问题。 3.4使用 select 语句处理多 Channel 和超时 当 Goroutine 需要同时监听多个 Channel 的读写操作时，必须使用 select 语句。\nselect 语句可以实现： 监听多个输入 Channel。 监听多个输出 Channel。 通过 default 块实现非阻塞操作。 结合 time.After 实现超时（Timeout）机制。 具体实现\nselect { case msg := \u0026lt;-ch1: // 接收到 ch1 的数据 case ch2 \u0026lt;- \u0026#34;hi\u0026#34;: // 成功发送数据到 ch2 case \u0026lt;-time.After(5 * time.Second): // 超时处理 default: // 如果没有任何 Channel 准备好，立即执行 default (非阻塞) } ","permalink":"https://mugong-song.github.io/blog/posts/chan_usage/","summary":"\u003cblockquote\u003e\n\u003cp\u003echan 是 Go 语言并发编程中最核心的概念之一，它是 Channel（通道） 类型的关键字缩写。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003cblockquote\u003e\n\u003cp\u003eChannel 的设计理念源于通信顺序进程（CSP, Communicating Sequential Processes），它提供了一种安全、同步的方式，让不同的 Goroutine（并发执行的“工人”）之间可以进行通信和数据交换。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"1什么是-chan-通道\"\u003e1.什么是 chan (通道)？\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eChannel 可以被理解为一个管道或队列，它具有以下核心特性：\u003c/strong\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e类型安全： Channel 只能传输它在创建时指定的特定类型的数据。\n例如：chan int 只能传输 int 整数。\n同步机制： Channel 默认会阻塞发送和接收操作，直到另一端准备好。\n并发安全： Go 运行时保证了对 Channel 的发送和接收操作是线程安全的，无需额外的锁（sync.Mutex）。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"2chan-怎么使用\"\u003e2.chan 怎么使用？\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e使用 Channel 主要分为三个步骤：创建、发送、接收。\u003c/strong\u003e\u003c/p\u003e\n\u003ch4 id=\"21-创建-channel\"\u003e2.1 创建 Channel\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003e使用 make 函数创建 Channel。\u003c/strong\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e//无缓冲通道 (Unbuffered)\nch := make(chan Type)\n//容量为 0。发送和接收操作必须同时准备好，否则先执行的操作会一直阻塞，直到另一个操作发生。用于严格的同步。\n\nch := make(chan Type, N)\n//有缓冲通道 (Buffered)\n//容量为 N。通道可以存储 N个元素。只有当通道满了（发送）或空了（接收）时，操作才会阻塞。用于解耦和提高吞吐量。\n\ndataCh := make(chan string)       // 无缓冲，用于同步信号\ntaskCh := make(chan int, 10)      // 有缓冲，容量为 10，用于传输任务\n\u003c/code\u003e\u003c/pre\u003e\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: left\"\u003e类型\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e语法\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e目的\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003cstrong\u003e切片\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003emake([]Type, length, capacity)\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e分配底层数组，设置切片的长度和容量。\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003cstrong\u003e映射\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003emake(map[KeyType]ValueType, capacity)\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e分配和初始化哈希表结构。\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003cstrong\u003e通道\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003emake(chan Type, capacity)\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e创建通道并设置其缓冲大小。\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch4 id=\"22-发送数据\"\u003e2.2 发送数据\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003e使用箭头操作符 \u0026lt;- 将数据发送到 Channel。\u003c/strong\u003e\u003c/p\u003e","title":"你会使用chan吗?"},{"content":"Go sheduler是什么? Go 程序的执行有两个层面：Go Program 和 Runtime，即用户程序和运行时。它们之间通过函数调用来实现内存管理、channel 通信、goroutine 创建等功能。用户程序进行的系统调用都会被 Runtime 拦截，以此来帮助它进行调度以及垃圾回收相关的工作。\nGo scheduler 可以说是 Go 运行时的一个最重要的 部分了。 Runtime 维护所有的 goroutine ，并通过 scheduler 来进行调度。goroutine 和 threads 是独立的， 但是 goroutine 要依赖 threads 才能执行。 Go 程序执行的高效和 scheduler 的调度是分不开的。 实际上在操作系统看来，所有的程序都是在执行多线程。将 goroutine 调度到线程上执行，仅仅是 runtime 层面的一个概念，在操作系统之上的层面，操作系统并不能感知到 goroutine 的存在。\nG、M、P三个基础的结构体来实现 goroutine 的调度： G 代表一个 goroutine，它包含：表示 goroutine 栈的一些字段，指示当前 goroutine 的状态，指示当前运行到的指令地址，也就是 PC 值。 M 表示内核线程，包含正在运行的 goroutine 等字段。 P 代表一个虚拟的CPU Processor，它维护一个处于 Runnable 状态的 goroutine 队列，M 需要获得 P 才能运行 G。 当然还有一个核心的结构体：sched，它总揽全局，维持整个调度器的运行。 Runtime 起始时会启动一些 G：垃圾回收的 G，执行调度的 G，运行用户代码的 G；并且会创建一 个 M 用来开始 G 的运行。随着时间的推移，G和M的创建数量逐渐增多。 在 Go 的早期版本，并没有 P 这个结构体，M 必须从一个全局的队列里获取要运行的 G，因此需要获取一个全局的锁，当并发量大的时候，锁就成了瓶颈。后来调度器在 Dmitry Vyukov (Go 语言运行时 runtime 和调度器的核心贡献者之一) ，加 上了 P 结构体。每个 P 维护一个处于 Runnable 状态的 G 的队列，解决了原来的全局锁问题。\nGo scheduler 的目标：将 goroutine 调度到内核线程上。 Go scheduler 的核心思想是： 1）重用线程。 2）限制同时运行（不包含阻塞）的线程数为 N，N 等于 CPU 的核心数目。 3）线程私有 runqueues，并且可以从其他线程偷取 goroutine 来运行，线程阻塞后，可以将 runqueues 传递给其他线程。 为什么需要 P 这个组件，直接把 runqueues 放到 M 不行吗？ 需要 P 组件的原因是当一个线程阻塞的时候，将和它绑定的 P 上的 goroutine 转移到其他线程。 例如当线程进行阻塞系统调用的时候，这时它无法再执行其他代码，因此可以将与其相关联的 P 上的 goroutine 分配给其他线程运行。 另外，Go scheduler 会启动一个后台线程 sysmon，用来检测长时间（超过 10 ms）运行的 goroutine，将其“停 靠”到 global runqueues。这是一个全局的 runqueue，优先级比较低，以示惩罚。 通常讲到 Go scheduler 都会提到 GPM 模型，来一 个个地看。\n","permalink":"https://mugong-song.github.io/blog/posts/gmp/","summary":"\u003ch3 id=\"go-sheduler是什么\"\u003eGo sheduler是什么?\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eGo 程序的执行有两个层面：Go Program 和 Runtime，即用户程序和运行时。它们之间通过函数调用来实现内存管理、channel 通信、goroutine 创建等功能。用户程序进行的系统调用都会被\nRuntime 拦截，以此来帮助它进行调度以及垃圾回收相关的工作。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eGo scheduler 可以说是 Go 运行时的一个最重要的 部分了。 Runtime 维护所有的 goroutine ，并通过\nscheduler 来进行调度。goroutine 和 threads 是独立的， 但是 goroutine 要依赖 threads 才能执行。\nGo 程序执行的高效和 scheduler 的调度是分不开的。\n实际上在操作系统看来，所有的程序都是在执行多线程。将 goroutine 调度到线程上执行，仅仅是 runtime\n层面的一个概念，在操作系统之上的层面，操作系统并不能感知到 goroutine 的存在。\u003c/p\u003e\n\u003ch3 id=\"gmp三个基础的结构体来实现-goroutine-的调度\"\u003eG、M、P三个基础的结构体来实现 goroutine 的调度：\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eG 代表一个 goroutine，它包含：表示 goroutine 栈的一些字段，指示当前 goroutine 的状态，指示当前运行到的指令地址，也就是 PC 值。\nM 表示内核线程，包含正在运行的 goroutine 等字段。\nP 代表一个虚拟的CPU Processor，它维护一个处于 Runnable 状态的 goroutine 队列，M 需要获得 P 才能运行 G。\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e当然还有一个核心的结构体：sched，它总揽全局，维持整个调度器的运行。\nRuntime 起始时会启动一些 G：垃圾回收的 G，执行调度的 G，运行用户代码的 G；并且会创建一\n个 M 用来开始 G 的运行。随着时间的推移，G和M的创建数量逐渐增多。\n在 Go 的早期版本，并没有 P 这个结构体，M 必须从一个全局的队列里获取要运行的 G，因此需要获取一个全局的锁，当并发量大的时候，锁就成了瓶颈。后来调度器在 Dmitry Vyukov (Go 语言运行时 runtime 和调度器的核心贡献者之一) ，加\n上了 P 结构体。每个 P 维护一个处于 Runnable 状态的 G 的队列，解决了原来的全局锁问题。\u003c/p\u003e","title":"Go sheduler 是什么?"},{"content":" 内存对齐（Memory Alignment）是计算机系统架构和编程中的一个基本概念，它指的是数据在内存中的存储地址必须是某个值的整数倍。这个“某个值”通常是该数据类型的大小或其最大成员的大小（在结构体中）。\n通过分析以下具体实例加深内存对齐理解。\ntype itab struct { inter *interfacetype // 接口类型信息 _type *_type // 实现接口的具体类型信息 hash uint32 // 类型 hash 值 _ [4]byte fun [1]uintptr // 实现接口方法的函数地址 } 一、Go 的结构体内存布局规则 Go 里每个字段在内存中都有一个偏移量（offset），而编译器会自动插入 padding（填充字节），以保证每个字段都按其类型对齐（alignment）。\n规则大致是： 每个字段的起始地址必须是该字段类型的对齐倍数。 比如：uint32 对齐要求 4 字节，uintptr（在 64 位机上）对齐要求 8 字节。 整个结构体的大小必须是其内部最大对齐单位的整数倍。 编译器自动插入 padding 字节，但有时源码里会显式加 _ [N]byte 来占位或兼容 ABI。\n二、itab 的字段分析（以 64位架构为例） 我们来计算每个字段的内存偏移：\n字段 类型 大小 (Size) 自身对齐值 (Align) 偏移量 (Offset)单位:字节 备注 inter *interfacetype 8 字节 8 字节 0 → 8 8 字节对齐 _type *_type 8 字节 8 字节 8→16 8 是 8 的倍数，已对齐 hash uint32 4 字节 4 字节 16→20 16 是 4 的倍数，已对齐 _ [4]byte 4 字节 1 字节 20→24 4 字节的填充 (Padding) fun [1]uintptr 8 字节 8 字节 24→32 8 字节对齐 24 是 8 的倍数 总大小32 字节，结构体最大对齐是 8 字节，总大小 32 是 8 的倍数。\n三、分析 [4]byte 实现对齐的机制这里的关键是：\n[4]byte 本身不实现对齐，它的存在是作为填充（Padding），从而保证其后续字段 fun 的对齐。 1.目标：fun [1]uintptr 字段是一个 uintptr 数组，在 64 位系统上，uintptr 是 8 字节，所以它必须从一个 8 字节对齐的地址开始。 2.计算： 到 hash 字段结束时，结构体的总大小为 8 + 8 + 4 = 20 字节。 下一个 8 字节对齐的地址是 24 ( 20 之后的第一个 8 的倍数)。 因此，需要在 hash 之后和 fun 之前插入 24 - 20 = 4 字节的填充。 3.实现：Go 源码通过显式地添加一个占位符字段 _ [4]byte 来实现这 4 字节的填充，从而确保 fun [1]uintptr 能够从 24 字节的偏移量开始，完美地实现 8 字节对齐。 四、Go 语言中的字段重排序方法 在 Go 中，重排序字段以实现内存优化的基本原则是：将占用内存空间小的字段（即对齐要求小的字段）放在前面，然后依次放置占用空间大的字段。\n优化规则（降序排列）： 最有效的排序策略是：将结构体中的字段按它们自身大小（即对齐要求）从大到小排列。 字段大小对齐要求 常用类型 优先级 最大 (8 字节) int64, float64, uint64, 指针类型 (*T), string, slice, interface 高 (先放) 中等 (4 字节) int32, float32, uint32 中 最小 (2 字节) int16, uint16 低 最小 (1 字节) bool, int8, uint8, byte 最低 (后放) ","permalink":"https://mugong-song.github.io/blog/posts/memory_alignment/","summary":"\u003cblockquote\u003e\n\u003cp\u003e内存对齐（Memory Alignment）是计算机系统架构和编程中的一个基本概念，它指的是数据在内存中的存储地址必须是某个值的整数倍。这个“某个值”通常是该数据类型的大小或其最大成员的大小（在结构体中）。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e通过分析以下具体实例加深内存对齐理解。\u003c/strong\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003etype itab struct {\n    inter *interfacetype // 接口类型信息\n    _type *_type         // 实现接口的具体类型信息\n    hash  uint32         // 类型 hash 值\n    _     [4]byte\n    fun   [1]uintptr     // 实现接口方法的函数地址\n}\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"一go-的结构体内存布局规则\"\u003e一、Go 的结构体内存布局规则\u003c/h2\u003e\n\u003cp\u003eGo 里每个字段在内存中都有一个偏移量（offset），而编译器会自动插入 padding（填充字节），以保证每个字段都按其类型对齐（alignment）。\u003c/p\u003e\n\u003cp\u003e规则大致是：\n每个字段的起始地址必须是该字段类型的对齐倍数。\n比如：uint32 对齐要求 4 字节，uintptr（在 64 位机上）对齐要求 8 字节。\n整个结构体的大小必须是其内部最大对齐单位的整数倍。\n编译器自动插入 padding 字节，但有时源码里会显式加 _ [N]byte 来占位或兼容 ABI。\u003c/p\u003e\n\u003ch2 id=\"二itab-的字段分析以-64位架构为例\"\u003e二、itab 的字段分析（以 64位架构为例）\u003c/h2\u003e\n\u003cp\u003e我们来计算每个字段的内存偏移：\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: left\"\u003e字段\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e类型\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e大小 (Size)\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e自身对齐值 (Align)\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e偏移量 (Offset)\u003cbr/\u003e单位:字节\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e备注\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003einter\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003e*interfacetype\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e8 字节\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e8 字节\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e0 → 8\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e8 字节对齐\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003e_type\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003e*_type\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e8 字节\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e8 字节\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e8→16\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e8  是  8  的倍数，已对齐\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003ehash\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003euint32\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e4 字节\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e4 字节\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e16→20\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e16  是  4  的倍数，已对齐\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003e_\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003e[4]byte\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e4 字节\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e1 字节\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e20→24\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e4 字节的填充 (Padding)\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003efun\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003e[1]uintptr\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e8 字节\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e8 字节\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e24→32\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e8 字节对齐  24  是  8  的倍数\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e总大小32 字节，结构体最大对齐是 8 字节，总大小 32 是 8 的倍数。\u003c/p\u003e","title":"内存对齐（memory alignment）"},{"content":" 主键（Primary Key）是唯一标识每行的非空字段，每表只能有一个； 唯一键（Unique Key）是保证字段值唯一，但允许为NULL，每表可有多个。\n主键 (Primary Key) 定义：用于唯一标识表中每一行数据的字段或字段组合，是表的核心标识。 作用：为其他表提供关联引用的核心字段，唯一标识表中的每一行数据。 特点 唯一性：所有主键值必须唯一，不可重复。 非空性：主键字段禁止为 NULL。 单例性：每张表仅能定义一个主键（但可以是多字段的联合主键）。 索引支持：数据库一般会为主键自动创建索引来提高查询效率。\n唯一键 (Unique Key) 定义：用于确保字段或字段组合的值唯一，但非表的唯一标识。 作用：提供辅助的唯一性约束，便于业务逻辑使用。确保指定列或列组合在表中的数据唯一，防止重复数据产生。 特点 唯一性：字段值不可重复，但允许 NULL，具体可允许多少个 NULL，取决于数据库实现，如 MySQL 可以有多个。 多例性：一张表可定义多个唯一键，用来约束不同的业务属性。 索引支持：数据库也通常会为唯一键创建索引，提高检索速度。\n主要区别 数量限制 主键：每张表只能有一个。 唯一键：一张表可以定义多个。\n用途侧重 主键：这一列（或列组合）在逻辑上就是记录的“身份证”，最常用来建立实体与实体间的关联。 唯一键：更多是防止重复数据，保证业务字段（如邮箱、手机号等）具有唯一性，但并非必然用作数据行的主标识。\n约束规则 主键：强制非空（NOT NULL），插入数据时必须显式指定值，但若设置 AUTO_INCREMENT，MySQL 会自动分配下一个可用值。插入后通常不推荐更新主键值。 唯一键：允许 NULL 值，例如：MySQL允许多个 NULL视为不冲突而SQL Server仅允许一个 NULL。值可更新，但需保证新值唯一。\n索引与性能 主键：默认创建聚集索引（如 MySQL InnoDB 、SQL Server），物理上按主键顺序存储数据，范围查询非常高效。 唯一键：默认创建非聚集索引，逻辑上维护唯一性，适合等值查询。\n简单示例 主键场景：在“用户表”中，UserID 作为主键，保证每位用户都能被独一无二地识别和引用。 唯一键场景：在同一个用户表中，Email 字段也要求不能重复时，就可以为 Email 设置唯一键；此时允许它为 NULL，但实际业务上通常会要求非 NULL 并且唯一。 总结\n主键和唯一键都用于保证数据唯一性，但主键更侧重于表的标识和引用，而唯一键更侧重于业务属性的唯一性约束。在实际应用中，通常会结合使用两者来实现数据完整性和业务规则的约束。\n主键其实就是用来标识每行数据身份的核心字段或字段组合，必须保证主键值的非空性和唯一性。非空性是指插入主键值数据时必须显式指定值，但如果设置了自增（AUTO_INCREMENT），插入数据时就不用手动指定值，数据库会自动分配下一个可用的数值，另外通常不建议在插入后再去修改主键。唯一性是指主键值数据整能够唯一标识表中的一行，此外数据库一般会自动给它创建聚簇索引。 相比之下，唯一键虽然也要保证相应字段的值的唯一性，但它更偏向业务层面的唯一性控制，不一定要当成每行数据的主识别字段。它允许为空，而且在不同的数据库里，对空值的处理也不一样，有的可以插入多个空值，例如MySQL。有的只能插一次，例如SQL Server 。一个表中可以同时存在多个唯一键，每个唯一键都会有对应的非聚簇索引来提升检索效率，这样就能在业务里确保不同属性都能做到唯一。 两者主要区别，首先是每张表只能有一个主键，但可以有多个唯一键。 其次是主键一定不能为空，而唯一键通常允许空值。 还有，主键往往是用来跟别的表建立关联，比如用户表中的 UserID 作为主键，就能让其他表引用这个字段来关联用户信息。唯一键更多是防止个别业务字段的重复，比如用户表中的 Email 地址如果也要求唯一，可以设置成唯一键，这样就能保证任何两个用户都不会用到相同的邮箱。 最后，数据库在主键和唯一键上也有不同的索引方式，InnoDB 或 SQL Server 的主键会采用聚集索引，让物理存储和主键顺序相关联，范围查询时会更高效；而唯一键通常是非聚集索引，比较侧重等值查询。 总之，主键和唯一键都用于保证数据唯一性，但主键更侧重于表的标识和引用，而唯一键更侧重于业务属性的唯一性约束。在实际应用中，通常会结合使用两者来实现数据完整性和业务规则的约束。 ","permalink":"https://mugong-song.github.io/blog/posts/sql_key/","summary":"\u003cblockquote\u003e\n\u003cp\u003e主键（Primary Key）是唯一标识每行的非空字段，每表只能有一个；\n唯一键（Unique Key）是保证字段值唯一，但允许为NULL，每表可有多个。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"主键-primary-key\"\u003e主键 (Primary Key)\u003c/h2\u003e\n\u003ch5 id=\"定义用于唯一标识表中每一行数据的字段或字段组合是表的核心标识\"\u003e定义：用于唯一标识表中每一行数据的字段或字段组合，是表的核心标识。\u003c/h5\u003e\n\u003ch5 id=\"作用为其他表提供关联引用的核心字段唯一标识表中的每一行数据\"\u003e作用：为其他表提供关联引用的核心字段，唯一标识表中的每一行数据。\u003c/h5\u003e\n\u003ch5 id=\"特点\"\u003e特点\u003c/h5\u003e\n\u003cp\u003e唯一性：所有主键值必须唯一，不可重复。\n非空性：主键字段禁止为 NULL。\n单例性：每张表仅能定义一个主键（但可以是多字段的联合主键）。\n索引支持：数据库一般会为主键自动创建索引来提高查询效率。\u003c/p\u003e\n\u003ch2 id=\"唯一键-unique-key\"\u003e唯一键 (Unique Key)\u003c/h2\u003e\n\u003ch5 id=\"定义用于确保字段或字段组合的值唯一但非表的唯一标识\"\u003e定义：用于确保字段或字段组合的值唯一，但非表的唯一标识。\u003c/h5\u003e\n\u003ch5 id=\"作用提供辅助的唯一性约束便于业务逻辑使用确保指定列或列组合在表中的数据唯一防止重复数据产生\"\u003e作用：提供辅助的唯一性约束，便于业务逻辑使用。确保指定列或列组合在表中的数据唯一，防止重复数据产生。\u003c/h5\u003e\n\u003ch5 id=\"特点-1\"\u003e特点\u003c/h5\u003e\n\u003cp\u003e唯一性：字段值不可重复，但允许 NULL，具体可允许多少个 NULL，取决于数据库实现，如 MySQL 可以有多个。\n多例性：一张表可定义多个唯一键，用来约束不同的业务属性。\n索引支持：数据库也通常会为唯一键创建索引，提高检索速度。\u003c/p\u003e\n\u003ch2 id=\"主要区别\"\u003e主要区别\u003c/h2\u003e\n\u003ch5 id=\"数量限制\"\u003e数量限制\u003c/h5\u003e\n\u003cp\u003e主键：每张表只能有一个。\n唯一键：一张表可以定义多个。\u003c/p\u003e\n\u003ch5 id=\"用途侧重\"\u003e用途侧重\u003c/h5\u003e\n\u003cp\u003e主键：这一列（或列组合）在逻辑上就是记录的“身份证”，最常用来建立实体与实体间的关联。\n唯一键：更多是防止重复数据，保证业务字段（如邮箱、手机号等）具有唯一性，但并非必然用作数据行的主标识。\u003c/p\u003e\n\u003ch5 id=\"约束规则\"\u003e约束规则\u003c/h5\u003e\n\u003cp\u003e主键：强制非空（NOT NULL），插入数据时必须显式指定值，但若设置 AUTO_INCREMENT，MySQL 会自动分配下一个可用值。插入后通常不推荐更新主键值。\n唯一键：允许 NULL 值，例如：MySQL允许多个 NULL视为不冲突而SQL Server仅允许一个 NULL。值可更新，但需保证新值唯一。\u003c/p\u003e\n\u003ch5 id=\"索引与性能\"\u003e索引与性能\u003c/h5\u003e\n\u003cp\u003e主键：默认创建聚集索引（如 MySQL InnoDB 、SQL Server），物理上按主键顺序存储数据，范围查询非常高效。\n唯一键：默认创建非聚集索引，逻辑上维护唯一性，适合等值查询。\u003c/p\u003e\n\u003ch2 id=\"简单示例\"\u003e简单示例\u003c/h2\u003e\n\u003cp\u003e主键场景：在“用户表”中，UserID 作为主键，保证每位用户都能被独一无二地识别和引用。\n唯一键场景：在同一个用户表中，Email 字段也要求不能重复时，就可以为 Email 设置唯一键；此时允许它为 NULL，但实际业务上通常会要求非 NULL 并且唯一。\n总结\u003c/p\u003e\n\u003cp\u003e主键和唯一键都用于保证数据唯一性，但主键更侧重于表的标识和引用，而唯一键更侧重于业务属性的唯一性约束。在实际应用中，通常会结合使用两者来实现数据完整性和业务规则的约束。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e主键其实就是用来标识每行数据身份的核心字段或字段组合，必须保证主键值的非空性和唯一性。非空性是指插入主键值数据时必须显式指定值，但如果设置了自增（AUTO_INCREMENT），插入数据时就不用手动指定值，数据库会自动分配下一个可用的数值，另外通常不建议在插入后再去修改主键。唯一性是指主键值数据整能够唯一标识表中的一行，此外数据库一般会自动给它创建聚簇索引。\n\n相比之下，唯一键虽然也要保证相应字段的值的唯一性，但它更偏向业务层面的唯一性控制，不一定要当成每行数据的主识别字段。它允许为空，而且在不同的数据库里，对空值的处理也不一样，有的可以插入多个空值，例如MySQL。有的只能插一次，例如SQL Server 。一个表中可以同时存在多个唯一键，每个唯一键都会有对应的非聚簇索引来提升检索效率，这样就能在业务里确保不同属性都能做到唯一。\n\n两者主要区别，首先是每张表只能有一个主键，但可以有多个唯一键。\n\n其次是主键一定不能为空，而唯一键通常允许空值。\n\n还有，主键往往是用来跟别的表建立关联，比如用户表中的 UserID 作为主键，就能让其他表引用这个字段来关联用户信息。唯一键更多是防止个别业务字段的重复，比如用户表中的 Email 地址如果也要求唯一，可以设置成唯一键，这样就能保证任何两个用户都不会用到相同的邮箱。\n\n最后，数据库在主键和唯一键上也有不同的索引方式，InnoDB 或 SQL Server 的主键会采用聚集索引，让物理存储和主键顺序相关联，范围查询时会更高效；而唯一键通常是非聚集索引，比较侧重等值查询。\n\n总之，主键和唯一键都用于保证数据唯一性，但主键更侧重于表的标识和引用，而唯一键更侧重于业务属性的唯一性约束。在实际应用中，通常会结合使用两者来实现数据完整性和业务规则的约束。\n\u003c/code\u003e\u003c/pre\u003e","title":"主键和唯一键？区别是什么？"},{"content":" 在 Go 后端开发中，我们通常使用 MySQL 或 PostgreSQL 等关系型数据库，索引设计的好坏直接决定了服务接口的响应速度。\n1.索引设计 1.1 选择合适的列作为索引： 选择性高（High Selectivity）： 索引列的不重复值越多越好。例如，用户 ID（唯一）比性别（只有两三种值）更适合作为索引。 场景： 在设计用户服务时，user_id、email 等是理想的索引列。 常用作查询条件（Where）： 经常出现在 WHERE 子句中的列，或者用于连接（JOIN）的列。 排序/分组（Order By/Group By）： 经常用于排序或分组的列。 1.2 考虑联合索引（Composite Index）： 最左前缀原则 (Leftmost Prefix Principle)： 这是联合索引设计的核心。如果创建了 (A, B, C) 的联合索引，它可以用于查询 WHERE A = ?、WHERE A = ? AND B = ?、WHERE A = ? AND B = ? AND C = ?，但不能单独用于 WHERE B = ? 或 WHERE C = ?。 场景： 在设计订单查询接口时，如果经常查询 WHERE user_id = ? AND order_status = ?，应建立 (user_id, order_status) 的联合索引。 1.3 覆盖索引 (Covering Index)： 如果查询的所有字段都包含在索引中，那么数据库不需要回表（查找主键对应的数据行），直接从索引中返回数据即可。这能大幅提升性能。 场景： 当你需要查询某个用户的订单状态和创建时间，只创建 (user_id, status, create_time) 的联合索引。查询语句为 SELECT status, create_time FROM orders WHERE user_id = ?，数据库直接通过索引就能拿到结果。 1.4 索引数量的平衡： 索引不是越多越好。每个索引都会占用磁盘空间，并且在进行 INSERT, UPDATE, DELETE 操作时，数据库需要维护索引，造成写操作性能下降。 场景： 在设计高写入量的日志表或消息表时，应尽量少建索引，只保留用于最核心查询的索引。 2.高效命中策略 使用 Explain ： 在 Go 后端进行复杂查询优化时，一定要在测试环境使用 EXPLAIN 命令分析 SQL 语句，确保 type 列不是 ALL（全表扫描），key 列使用了正确的索引。\nGo 代码中遵循 最左前缀原则 ： 确保在 Go 代码中构造查询条件时，联合索引的最左侧列总是被包含。\n// 假设索引为 (user_id, status, created_at) // 高效命中：查询中包含 user_id db.Where(\u0026#34;user_id = ? AND status = ?\u0026#34;, userID, status).Find(\u0026amp;orders) // 命中索引的前缀 (user_id)：虽然没有 status，但仍然高效。 db.Where(\u0026#34;user_id = ?\u0026#34;, userID).Find(\u0026amp;orders) // 低效/索引失效：查询中不包含 user_id db.Where(\u0026#34;status = ?\u0026#34;, status).Find(\u0026amp;orders) // 仅 status 无法利用联合索引 // 3.导致索引失效 3.1 导致索引失效的常见方式 索引失效意味着查询优化器放弃使用索引，转而进行全表扫描（ALL），这是后端服务产生慢查询的主要原因。\n失效方式 示例 SQL 为什么失效？ Go 后端实践建议 对索引列进行函数操作 WHERE YEAR(create_time) = 2024 数据库需要对每一行的 create_time 执行 YEAR() 函数，无法直接通过索引 B+ Tree 结构查找。 应将函数操作放在等号右侧：\nWHERE create_time \u0026gt;= '2024-01-01' AND create_time \u0026lt; '2025-01-01' LIKE 模糊查询开头 WHERE username LIKE '%zhangsan' 百分号 % 在左侧，导致无法利用 B+ Tree 的有序性进行快速查找。 尽量使用前缀匹配：\nWHERE username LIKE 'zhangsan%'。如果必须使用左模糊，考虑使用 Elasticsearch 或其他全文检索方案。 类型转换（隐式转换） WHERE phone = 13800001111（phone 字段是 VARCHAR） 字符串字段和数字进行比较，MySQL 会将字符串隐式转换为数字，相当于对索引列进行了函数操作。 在 Go 代码中严格控制数据类型，使用字符串参数进行查询：\ndb.Where(\u0026quot;phone = ?\u0026quot;, \u0026quot;13800001111\u0026quot;)。 使用 OR 连接条件 WHERE name = 'A' OR age = 18 如果 name 和 age 字段都没有索引或索引类型不匹配，优化器倾向于全表扫描。 如果两个列都有索引，有时会采用索引合并；但更推荐将 OR 拆分为两个 UNION 查询。 违反最左前缀原则 联合索引 (A, B, C)，查询 WHERE B = ? AND C = ? 跳过联合索引的最左侧列 A，B+ Tree 无法按顺序查找。 检查联合索引的设计和查询语句，确保查询条件涵盖联合索引的左侧列。 使用负向查询 WHERE status != 0 或 WHERE col NOT IN (1, 2) 负向查询覆盖了大部分数据，优化器认为全表扫描更快。 尽量使用正向查询：\nWHERE status IN (1, 2, 3)。 ","permalink":"https://mugong-song.github.io/blog/posts/sql_index/","summary":"\u003cblockquote\u003e\n\u003cp\u003e在 Go 后端开发中，我们通常使用 MySQL 或 PostgreSQL 等关系型数据库，索引设计的好坏直接决定了服务接口的响应速度。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"1索引设计\"\u003e1.索引设计\u003c/h3\u003e\n\u003ch4 id=\"11-选择合适的列作为索引\"\u003e1.1 选择合适的列作为索引：\u003c/h4\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e选择性高（High Selectivity）： 索引列的不重复值越多越好。例如，用户 ID（唯一）比性别（只有两三种值）更适合作为索引。\n场景： 在设计用户服务时，user_id、email 等是理想的索引列。\n常用作查询条件（Where）： 经常出现在 WHERE 子句中的列，或者用于连接（JOIN）的列。\n排序/分组（Order By/Group By）： 经常用于排序或分组的列。\n\u003c/code\u003e\u003c/pre\u003e\u003ch4 id=\"12-考虑联合索引composite-index\"\u003e1.2 考虑联合索引（Composite Index）：\u003c/h4\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e最左前缀原则 (Leftmost Prefix Principle)： 这是联合索引设计的核心。如果创建了 (A, B, C) 的联合索引，它可以用于查询 WHERE A = ?、WHERE A = ? AND B = ?、WHERE A = ? AND B = ? AND C = ?，但不能单独用于 WHERE B = ? 或 WHERE C = ?。\n场景： 在设计订单查询接口时，如果经常查询 WHERE user_id = ? AND order_status = ?，应建立 (user_id, order_status) 的联合索引。\n\u003c/code\u003e\u003c/pre\u003e\u003ch4 id=\"13-覆盖索引-covering-index\"\u003e1.3 覆盖索引 (Covering Index)：\u003c/h4\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e如果查询的所有字段都包含在索引中，那么数据库不需要回表（查找主键对应的数据行），直接从索引中返回数据即可。这能大幅提升性能。\n场景： 当你需要查询某个用户的订单状态和创建时间，只创建 (user_id, status, create_time) 的联合索引。查询语句为 SELECT status, create_time FROM orders WHERE user_id = ?，数据库直接通过索引就能拿到结果。\n\u003c/code\u003e\u003c/pre\u003e\u003ch4 id=\"14-索引数量的平衡\"\u003e1.4 索引数量的平衡：\u003c/h4\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e索引不是越多越好。每个索引都会占用磁盘空间，并且在进行 INSERT, UPDATE, DELETE 操作时，数据库需要维护索引，造成写操作性能下降。\n场景： 在设计高写入量的日志表或消息表时，应尽量少建索引，只保留用于最核心查询的索引。\n\u003c/code\u003e\u003c/pre\u003e\u003chr\u003e\n\u003ch3 id=\"2高效命中策略\"\u003e2.高效命中策略\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e使用 Explain ： 在 Go 后端进行复杂查询优化时，一定要在测试环境使用 EXPLAIN 命令分析 SQL 语句，确保 type 列不是 ALL（全表扫描），key 列使用了正确的索引。\u003c/strong\u003e\u003c/p\u003e","title":"SQL_Index 索引"},{"content":" Go 语言里 slice 和 map 是非常有用的两个内置数据结构， 线上的工程代码几乎不可能绕开它们。\n1.数组与切片 因为切片（slice）比数组更好用，也更安全，Go 推荐使用 slice 而不是数组。本节内容比较 了 slice 和数组的区别，也研究了 slice 的一些特有的性质。\n1.1数组和切片有何异同 Go 语言中的切片（slice）结构的本质是对数组的封装，它描述一个数组的片段。无论是数组 还是切片，都可以通过下标来访问单个元素。 数组是定长的，长度定义好之后，不能再更改。在 Go 语言中，数组是不常见的，因为其长度 是类型的一部分，限制了它的表达能力，比如 [3]int 和 [4]int 就是不同的类型。而切片则非常灵 活，它可以动态地扩容，且切片的类型和长度无关。\nfunc main() { arr1 := [1]int{1} arr2 := [2]int{1, 2} if arr1 == arr2 { fmt.Println(\u0026quot;equal type\u0026quot;) } } 尝试运行，报编译错误：\n./test.go:16:10: invalid operation: arr1 == arr2 (mismatched types [1]int and [2]int) 因为两个数组的长度不同，根本就不是同一类型，因此不能进行比较。 数组是一片连续的内存，切片实际上是一个结构体，包含三个字段：长度、容量、底层数组。\n// src/runtime/slice.go type slice struct { array unsafe.Pointer // 元素指针 len int // 长度 cap int // 容量 } 注意，底层数组可以被多个切片同时指向，因此对一个切 片的元素进行操作有可能会影响到其他切片。\n1.2切片如何被截取 截取也是一种比较常见的创建 slice 的方法，可以从数组或者 slice 直接截取，需要指定起、 止索引位置。 基于已有 slice 创建新 slice 对象，被称为 reslice。新 slice 和老 slice 共用底层数组，新老 slice 对底层数组的更改都会影响到彼此。基于数组创建的新 slice 也是同样的效果：对数组或 slice 元素做的更改都会影响到彼此。 值得注意的是，新老 slice 或者新 slice 老数组互相影响的前提是两者共用底层数组，如果因 为执行 append 操作使得新 slice 或老 slice 底层数组扩容，移动到了新的位置，两者就不会相互影 响了。所以，问题的关键在于两者是否会共用底层数组。\ndata := [...]int{0, 1, 2, 3, 4, 5, 6, 7, 8, 9} slice := data[2:4:6] // data[low, high, max 对 data 使用 3 个索引值，截取出新的 slice。这里 data 可以是数组或者 slice。low 是最低索引 值，这里是闭区间，也就是说第一个元素是 data 位于 low 索引处的元素；而 high 和 max 则是开区 间，表示最后一个元素只能是索引 high-1 处的元素，而最大容量则只能是索引 max-1 处的元素。 要求：max \u0026gt;= high \u0026gt;= low 当 high == low 时，新 slice 为空。\n","permalink":"https://mugong-song.github.io/blog/posts/slice_01/","summary":"\u003cblockquote\u003e\n\u003cp\u003eGo 语言里 slice 和 map 是非常有用的两个内置数据结构，\n线上的工程代码几乎不可能绕开它们。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"1数组与切片\"\u003e1.数组与切片\u003c/h3\u003e\n\u003cp\u003e因为切片（slice）比数组更好用，也更安全，Go 推荐使用 slice 而不是数组。本节内容比较\n了 slice 和数组的区别，也研究了 slice 的一些特有的性质。\u003c/p\u003e\n\u003ch4 id=\"11数组和切片有何异同\"\u003e1.1数组和切片有何异同\u003c/h4\u003e\n\u003cp\u003eGo 语言中的切片（slice）结构的本质是对数组的封装，它描述一个数组的片段。无论是数组\n还是切片，都可以通过下标来访问单个元素。\n数组是定长的，长度定义好之后，不能再更改。在 Go 语言中，数组是不常见的，因为其长度\n是类型的一部分，限制了它的表达能力，比如 [3]int 和 [4]int 就是不同的类型。而切片则非常灵\n活，它可以动态地扩容，且切片的类型和长度无关。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003efunc main() { \n    arr1 := [1]int{1}\n    arr2 := [2]int{1, 2}\n    if arr1 == arr2 {\n    fmt.Println(\u0026quot;equal type\u0026quot;)\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e尝试运行，报编译错误：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e./test.go:16:10: invalid operation: arr1 == arr2 (mismatched types [1]int and [2]int)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e因为两个数组的长度不同，根本就不是同一类型，因此不能进行比较。\n数组是一片连续的内存，切片实际上是一个结构体，包含三个字段：长度、容量、底层数组。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e// src/runtime/slice.go\n    type slice struct {\n    array unsafe.Pointer // 元素指针\n    len int // 长度\n    cap int // 容量\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e注意，底层数组可以被多个切片同时指向，因此对一个切\n片的元素进行操作有可能会影响到其他切片。\u003c/p\u003e","title":"slice 和 数组"},{"content":"今天开始记录我在 Go 高并发项目中的一些心得体会。\n","permalink":"https://mugong-song.github.io/blog/posts/fist-blog/","summary":"\u003cp\u003e今天开始记录我在 Go 高并发项目中的一些心得体会。\u003c/p\u003e","title":"我的第一篇博客"},{"content":"🚀 什么是 Hugo？ Hugo 是一个基于 Go 语言编写的 静态网站生成器。\n它的最大特点是——速度极快、部署方便、几乎零依赖。\n使用 Hugo，你可以用 Markdown 写文章，然后自动生成一个完整的博客网站。\n🛠️ 安装 Hugo 在 macOS 上：\nbrew install hugo ","permalink":"https://mugong-song.github.io/blog/posts/%E5%88%9D%E8%AF%86-hugo%E6%89%93%E9%80%A0%E4%BD%A0%E7%9A%84%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2/","summary":"\u003ch2 id=\"-什么是-hugo\"\u003e🚀 什么是 Hugo？\u003c/h2\u003e\n\u003cp\u003eHugo 是一个基于 Go 语言编写的 \u003cstrong\u003e静态网站生成器\u003c/strong\u003e。\u003cbr\u003e\n它的最大特点是——\u003cstrong\u003e速度极快、部署方便、几乎零依赖\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e使用 Hugo，你可以用 Markdown 写文章，然后自动生成一个完整的博客网站。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"-安装-hugo\"\u003e🛠️ 安装 Hugo\u003c/h2\u003e\n\u003cp\u003e在 macOS 上：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ebrew install hugo\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"First Encounter with Hugo"}]